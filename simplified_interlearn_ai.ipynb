{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMqL+lW2iP+8Ohg05co9fAW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BatXprO/batxpro.githib.io/blob/main/simplified_interlearn_ai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gTTS moviepy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qc9txwqVomNJ",
        "outputId": "cc41aaa3-9f06-47e7-9f42-f9bcb365ac1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gTTS\n",
            "  Downloading gTTS-2.5.1-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from gTTS) (2.31.0)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gTTS) (8.1.7)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.66.2)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from moviepy) (1.25.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.6)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.4.9)\n",
            "Requirement already satisfied: pillow<10.1.0,>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy) (9.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg>=0.2.0->moviepy) (67.7.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (2024.2.2)\n",
            "Installing collected packages: gTTS\n",
            "Successfully installed gTTS-2.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gtts import gTTS\n",
        "from moviepy.editor import *\n",
        "import os\n",
        "\n",
        "# Function to convert text to speech\n",
        "def text_to_speech(text, language='en', gender='male'):\n",
        "    tts = gTTS(text=text, lang=language, slow=False)\n",
        "    tts.save(\"temp.mp3\")\n",
        "\n",
        "# Function to create lip-synced video\n",
        "def create_video(text, image_path, output_path='output.mp4', language='en', gender='male'):\n",
        "    # Convert text to speech\n",
        "    text_to_speech(text, language, gender)\n",
        "\n",
        "    # Load the audio and image\n",
        "    audio = AudioFileClip(\"temp.mp3\")\n",
        "    image = ImageClip(image_path)\n",
        "\n",
        "    # Set the duration of the video equal to the duration of the audio\n",
        "    video = CompositeVideoClip([image.set_duration(audio.duration).set_audio(audio)])\n",
        "\n",
        "    # Write the video to the output path\n",
        "    video.write_videofile(output_path, fps=24, codec=\"libx264\", audio_codec=\"aac\")\n",
        "\n",
        "    # Clean up temporary files\n",
        "    os.remove(\"temp.mp3\")\n",
        "\n",
        "# Accept text input from user\n",
        "text = input(\"Enter the text for the video: \")\n",
        "\n",
        "# Path to the image\n",
        "image_path = '/content/Why-Become-A-Teacher-25-Compelling-Reasons.jpg'\n",
        "\n",
        "# Create the video\n",
        "create_video(text, image_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "07CTSwk1vE3q",
        "outputId": "69a6a7c5-2d06-431f-c9ac-ed19519a4f44"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the text for the video: The sun slowly dipped below the horizon, casting a golden glow across the tranquil waters. The sky transformed into a canvas of vibrant hues, painting a breathtaking scene. The gentle breeze carried the scent of blooming flowers, mingling with the earthy fragrance of the forest. Birds chirped their evening song, adding to the symphony of nature. A sense of peace enveloped the surroundings, calming the soul. Stars began to twinkle in the darkening sky, and the moon emerged, casting a soft, ethereal light. Time seemed to stand still, allowing a moment of pure serenity and awe-inspiring beauty.\"\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "No such file: '/content/Why-Become-A-Teacher-25-Compelling-Reasons.jpg'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-041f941c4ff1>\u001b[0m in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# Create the video\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mcreate_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-34-041f941c4ff1>\u001b[0m in \u001b[0;36mcreate_video\u001b[0;34m(text, image_path, output_path, language, gender)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Load the audio and image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAudioFileClip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"temp.mp3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageClip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Set the duration of the video equal to the duration of the audio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/moviepy/video/VideoClip.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, img, ismask, transparent, fromalpha, duration)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# img is (now) a RGB(a) numpy array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/imageio/__init__.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(uri, format, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m     )\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mimread_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/imageio/v2.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(uri, format, **kwargs)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0mimopen_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"legacy_mode\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mimopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ri\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mimopen_args\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/imageio/core/imopen.py\u001b[0m in \u001b[0;36mimopen\u001b[0;34m(uri, io_mode, plugin, extension, format_hint, legacy_mode, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_hint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat_hint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0mrequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_hint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat_hint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextension\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"<bytes>\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/imageio/core/request.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, uri, mode, extension, format_hint, **kwargs)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;31m# Parse what was given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_uri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;31m# Set extension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/imageio/core/request.py\u001b[0m in \u001b[0;36m_parse_uri\u001b[0;34m(self, uri)\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[0;31m# Reading: check that the file exists (but is allowed a dir)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No such file: '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m                 \u001b[0;31m# Writing: check that the directory to write to does exist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: No such file: '/content/Why-Become-A-Teacher-25-Compelling-Reasons.jpg'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gtts import gTTS\n",
        "from moviepy.editor import *\n",
        "import os\n",
        "\n",
        "# Function to convert text to speech\n",
        "def text_to_speech(text, language='en'):\n",
        "    tts = gTTS(text=text, lang=language, slow=False)\n",
        "    tts.save(\"temp.mp3\")\n",
        "\n",
        "# Function to create lip-synced video\n",
        "def create_video(text, image_path, output_path='output.mp4', language='en'):\n",
        "    # Convert text to speech\n",
        "    text_to_speech(text, language)\n",
        "\n",
        "    # Load the audio and image\n",
        "    audio = AudioFileClip(\"temp.mp3\")\n",
        "    image = ImageClip(image_path)\n",
        "\n",
        "    # Set the duration of the video equal to the duration of the audio\n",
        "    video = image.set_duration(audio.duration)\n",
        "\n",
        "    # Set the audio for the video\n",
        "    video = video.set_audio(audio)\n",
        "\n",
        "    # Create a sequence of talking mouths (replace with your own mouth images)\n",
        "    mouth_images = ['1.png', '2.png', '3.png']  # Example mouth images\n",
        "    mouth_clips = [ImageClip(mouth_image).set_duration(0.1) for mouth_image in mouth_images]\n",
        "    talking_mouth = concatenate_videoclips(mouth_clips, method=\"compose\")\n",
        "\n",
        "    # Overlay the talking mouth sequence onto the original image\n",
        "    final_video = CompositeVideoClip([video, talking_mouth.set_position(('center', 'bottom'))])\n",
        "\n",
        "    # Write the video to the output path\n",
        "    final_video.write_videofile(output_path, fps=24, codec=\"libx264\", audio_codec=\"aac\")\n",
        "\n",
        "    # Clean up temporary files\n",
        "    os.remove(\"temp.mp3\")\n",
        "\n",
        "# Accept text input from user\n",
        "text = input(\"Enter the text for the video: \")\n",
        "\n",
        "# Path to the image\n",
        "image_path = '/content/sample_data/images/1.png'\n",
        "\n",
        "# Create the video\n",
        "create_video(text, image_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCskq5bGxbL9",
        "outputId": "4fd456b9-67c0-4456-d836-bd12c34a5577"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the text for the video: I see, to add a lip-sync effect, we need to create a sequence of images that simulate mouth movements and overlay them onto the original image. This requires preparing a set of mouth images in advance. Here's an example of how you can achieve this:  Prepare a set of mouth images (e.g., mouth_1.png, mouth_2.png, etc.) representing different mouth positions for speech. Use these images to create a sequence that simulates talking. Overlay the talking mouth sequence onto the original image.\n",
            "Moviepy - Building video output.mp4.\n",
            "MoviePy - Writing audio in outputTEMP_MPY_wvf_snd.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video output.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready output.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gtts import gTTS\n",
        "from moviepy.editor import *\n",
        "import os\n",
        "\n",
        "# Function to convert text to speech\n",
        "def text_to_speech(text, language='en'):\n",
        "    tts = gTTS(text=text, lang=language, slow=False)\n",
        "    tts.save(\"temp.mp3\")\n",
        "\n",
        "# Function to create lip-synced video\n",
        "def create_video(text, image_path, output_path='output.mp4', language='en'):\n",
        "    # Convert text to speech\n",
        "    text_to_speech(text, language)\n",
        "\n",
        "    # Load the audio and image\n",
        "    audio = AudioFileClip(\"temp.mp3\")\n",
        "    image = ImageClip(image_path)\n",
        "\n",
        "    # Set the duration of the video equal to the duration of the audio\n",
        "    video = image.set_duration(audio.duration)\n",
        "\n",
        "    # Set the audio for the video\n",
        "    video = video.set_audio(audio)\n",
        "\n",
        "    # Create a sequence of talking mouths (replace with your own mouth images)\n",
        "    mouth_images = ['1.png', '2.png', '3.png']  # Example mouth images\n",
        "    mouth_clips = [ImageClip(mouth_image).set_duration(0.1) for mouth_image in mouth_images]\n",
        "\n",
        "    # Extend the last frame of the mouth image to match the duration of the audio\n",
        "    last_frame = ImageClip(mouth_images[-1]).set_duration(audio.duration - sum([clip.duration for clip in mouth_clips[:-1]]))\n",
        "    mouth_clips_extended = mouth_clips[:-1] + [last_frame]\n",
        "\n",
        "    # Create the talking mouth sequence\n",
        "    talking_mouth = concatenate_videoclips(mouth_clips_extended, method=\"compose\")\n",
        "\n",
        "    # Overlay the talking mouth sequence onto the original image\n",
        "    final_video = CompositeVideoClip([video, talking_mouth.set_position(('center', 'bottom'))])\n",
        "\n",
        "    # Write the video to the output path\n",
        "    final_video.write_videofile(output_path, fps=24, codec=\"libx264\", audio_codec=\"aac\")\n",
        "\n",
        "    # Clean up temporary files\n",
        "    os.remove(\"temp.mp3\")\n",
        "\n",
        "# Accept text input from user\n",
        "text = input(\"Enter the text for the video: \")\n",
        "\n",
        "# Path to the image\n",
        "image_path = '/content/sample_data/images/1.png'\n",
        "\n",
        "# Create the video\n",
        "create_video(text, image_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8cTiFMN1ON1",
        "outputId": "d83b018f-157e-450b-bf63-95fc454437c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the text for the video: This modification should ensure that the mouth movement continues for the duration of the audio. Adjust the mouth_images list and the duration of each frame as needed to match your specific mouth images and requirements.\n",
            "Moviepy - Building video output.mp4.\n",
            "MoviePy - Writing audio in outputTEMP_MPY_wvf_snd.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video output.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready output.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gtts import gTTS\n",
        "from moviepy.editor import *\n",
        "import os\n",
        "\n",
        "# Function to convert text to speech\n",
        "def text_to_speech(text, language='en'):\n",
        "    tts = gTTS(text=text, lang=language, slow=False)\n",
        "    tts.save(\"temp.mp3\")\n",
        "\n",
        "# Function to create video with three images\n",
        "def create_video(text, image_paths, output_path='output.mp4', language='en'):\n",
        "    # Convert text to speech\n",
        "    text_to_speech(text, language)\n",
        "\n",
        "    # Load the audio\n",
        "    audio = AudioFileClip(\"temp.mp3\")\n",
        "\n",
        "    # Calculate duration for each image based on the total audio duration and number of images\n",
        "    image_duration = audio.duration / len(image_paths)\n",
        "\n",
        "    # Create video with three images displayed sequentially\n",
        "    clips = []\n",
        "    for i, image_path in enumerate(image_paths):\n",
        "        image = ImageClip(image_path)\n",
        "        image = image.set_duration(image_duration)\n",
        "        clips.append(image)\n",
        "\n",
        "    video = concatenate_videoclips(clips)\n",
        "\n",
        "    # Set the audio for the video\n",
        "    video = video.set_audio(audio)\n",
        "\n",
        "    # Write the video to the output path\n",
        "    video.write_videofile(output_path, fps=24, codec=\"libx264\", audio_codec=\"aac\")\n",
        "\n",
        "    # Clean up temporary files\n",
        "    os.remove(\"temp.mp3\")\n",
        "\n",
        "# Accept text input from user\n",
        "text = input(\"Enter the text for the video: \")\n",
        "\n",
        "# Paths to the images\n",
        "image_paths = ['/content/sample_data/images/1.png', '/content/sample_data/images/2.png', '/content/sample_data/images/3.png']\n",
        "\n",
        "# Create the video\n",
        "create_video(text, image_paths)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0rLZcFn49e3",
        "outputId": "c2f471ba-1f41-40a0-96f8-e70fa8466a4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the text for the video: The sun slowly dipped below the horizon, casting a golden glow across the tranquil waters. The sky transformed into a canvas of vibrant hues, painting a breathtaking scene. The gentle breeze carried the scent of blooming flowers, mingling with the earthy fragrance of the forest. Birds chirped their evening song, adding to the symphony of nature. A sense of peace enveloped the surroundings, calming the soul. Stars began to twinkle in the darkening sky, and the moon emerged, casting a soft, ethereal light. Time seemed to stand still, allowing a moment of pure serenity and awe-inspiring beauty.\"\n",
            "Moviepy - Building video output.mp4.\n",
            "MoviePy - Writing audio in outputTEMP_MPY_wvf_snd.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video output.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready output.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gtts import gTTS\n",
        "from moviepy.editor import *\n",
        "import os\n",
        "\n",
        "# Function to convert text to speech\n",
        "def text_to_speech(text, language='en'):\n",
        "    tts = gTTS(text=text, lang=language, slow=False)\n",
        "    tts.save(\"temp.mp3\")\n",
        "\n",
        "# Function to create video with three images in a loop\n",
        "def create_video(text, image_paths, output_path='output.mp4', language='en'):\n",
        "    # Convert text to speech\n",
        "    text_to_speech(text, language)\n",
        "\n",
        "    # Load the audio\n",
        "    audio = AudioFileClip(\"temp.mp3\")\n",
        "\n",
        "    # Calculate duration for each image based on the total audio duration and number of images\n",
        "    image_duration = audio.duration / len(image_paths)\n",
        "\n",
        "    # Create video with three images displayed in a loop\n",
        "    clips = []\n",
        "    for i, image_path in enumerate(image_paths):\n",
        "        image = ImageClip(image_path)\n",
        "        image = image.set_duration(image_duration)\n",
        "        clips.append(image)\n",
        "\n",
        "    # Repeat the images to match the duration of the audio\n",
        "    repeated_clips = []\n",
        "    while sum([clip.duration for clip in repeated_clips]) < audio.duration:\n",
        "        repeated_clips.extend(clips)\n",
        "\n",
        "    video = concatenate_videoclips(repeated_clips)\n",
        "\n",
        "    # Set the audio for the video\n",
        "    video = video.set_audio(audio)\n",
        "\n",
        "    # Write the video to the output path\n",
        "    video.write_videofile(output_path, fps=24, codec=\"libx264\", audio_codec=\"aac\")\n",
        "\n",
        "    # Clean up temporary files\n",
        "    os.remove(\"temp.mp3\")\n",
        "\n",
        "# Accept text input from user\n",
        "text = input(\"Enter the text for the video: \")\n",
        "\n",
        "# Paths to the images\n",
        "image_paths = ['/content/1.png', '/content/2.png', '/content/3.png']\n",
        "\n",
        "# Create the video\n",
        "create_video(text, image_paths)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xpjq5UFJC9cv",
        "outputId": "1ecff88d-11d0-446c-fc76-9c7cb2a3933e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the text for the video: The sun slowly dipped below the horizon, casting a golden glow across the tranquil waters. The sky transformed into a canvas of vibrant hues, painting a breathtaking scene. The gentle breeze carried the scent of blooming flowers, mingling with the earthy fragrance of the forest. Birds chirped their evening song, adding to the symphony of nature. A sense of peace enveloped the surroundings, calming the soul. Stars began to twinkle in the darkening sky, and the moon emerged, casting a soft, ethereal light. Time seemed to stand still, allowing a moment of pure serenity and awe-inspiring beauty.\n",
            "Moviepy - Building video output.mp4.\n",
            "MoviePy - Writing audio in outputTEMP_MPY_wvf_snd.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video output.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready output.mp4\n"
          ]
        }
      ]
    }
  ]
}